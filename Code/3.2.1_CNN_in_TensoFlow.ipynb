{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feJbGGIm7gMG"
   },
   "source": [
    " Build CNN model using TensorFlow for MNIST problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AsW0S3vHI5MP"
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x65sciN7qWO"
   },
   "source": [
    "check the version of TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggZCRA365tll",
    "outputId": "5a35a82d-9adc-4707-d089-c13d6d5ab46e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "# version of tensorflow\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt_VewbS7t1m"
   },
   "source": [
    "Load the MNIST dataset using the datasets class of tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7ZNq2zd5xuy",
    "outputId": "082ad1a2-a8f0-4f18-b5da-e37642bec1ec"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data(path='mnist.npz')\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b9KriyD72UO"
   },
   "source": [
    "We have loaded the training as well as the test set of the MNIST dataset. Also, we have normalized the pixel values for both training as well as test images. Next, let’s visualize a few images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "iM9ZMacC50si",
    "outputId": "d1bac293-0255-4a0a-ab20-cac416a71135"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing a few images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3DFlskG784O"
   },
   "source": [
    "Subsequently, this is how our dataset looks like. We have images of handwritten digits. Let’s also look at the shapes of the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiG5vaUV54zq",
    "outputId": "65448b28-9055-4a55-82a9-09b93e608609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the training and test set\n",
    "(train_images.shape, train_labels.shape), (test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0cEoSUw8B2n"
   },
   "source": [
    "We have 60,000 images of shape 28 by 28 in the training set and 10,000 images of the same shape in the test set. Next, we will resize the shape of images and one-hot encode the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SB0EN0q66CL7"
   },
   "outputs": [],
   "source": [
    "# reshaping the images\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# one hot encoding the target variable\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7meROU28NY-"
   },
   "source": [
    "### Defining Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqwzhPh08K1e"
   },
   "source": [
    "Now, we will define the architecture of our model. So, our model will have 2 convolutional layers, with a combination of max-pooling layers, then we will have a flatten layer and finally a dense layer with 10 neurons since we have 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nSUmghJ06FHJ"
   },
   "outputs": [],
   "source": [
    "# defining the model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZhSZIkX8aBm"
   },
   "source": [
    "Quickly look at the summary of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKxmiCiu6JPp",
    "outputId": "5f54c312-baeb-424d-c6ea-539cb9486e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 4)         148       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 4)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198\n",
      "Trainable params: 1,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF7nVCH_8iOW"
   },
   "source": [
    "To summarize, we have 2 convolutional layers, 2 max-pooling layers, a flatten layer, and a dense layer. The total number of parameters in the model is 1,198. Now that our model is ready, we will compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7V7vDtTU6LoR"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0lJRdoi8oPO"
   },
   "source": [
    "We are using Adam optimizer, and you can change it as well. The loss function is set to be as categorical cross-entropy since we are solving a multi-class classification problem and the metric is accuracy. Now let’s train our model for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2Lrq-JF6Ob7",
    "outputId": "d373b93e-1c35-41d8-c6ec-e53c12f39a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4752 - accuracy: 0.8466 - val_loss: 0.2069 - val_accuracy: 0.9340\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1853 - accuracy: 0.9430 - val_loss: 0.1634 - val_accuracy: 0.9492\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1497 - accuracy: 0.9539 - val_loss: 0.1370 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1325 - accuracy: 0.9588 - val_loss: 0.1135 - val_accuracy: 0.9639\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1204 - accuracy: 0.9623 - val_loss: 0.1099 - val_accuracy: 0.9669\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1113 - accuracy: 0.9653 - val_loss: 0.0977 - val_accuracy: 0.9681\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1054 - accuracy: 0.9672 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0997 - accuracy: 0.9694 - val_loss: 0.0938 - val_accuracy: 0.9701\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0959 - accuracy: 0.9705 - val_loss: 0.0847 - val_accuracy: 0.9734\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0921 - accuracy: 0.9711 - val_loss: 0.0851 - val_accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ppW6kOs7TIW"
   },
   "source": [
    "To summarize, initially, the training loss was about 0.40 and after 10 epochs, the training loss reduced to 0.09. The training and validation accuracies after 10 epochs are 97.11% and 97.25% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGoIXG426Q2h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN in TensoFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
